{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用VGG13实现cifar数据集上的图像识别\n",
    "\n",
    "## The CIFAR-10 dataset\n",
    "\n",
    "**网址**：\n",
    "\n",
    "http://www.cs.toronto.edu/~kriz/cifar.html?usg=alkjrhjqbhw2llxlo8emqns-tbk0at96jq\n",
    "\n",
    "**介绍**：\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n",
    "\n",
    "<img src=\"CIFAR-10.PNG\" width=\"50%\">\n",
    "\n",
    "The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks.\n",
    "\n",
    "在TensorFlow中，通过datasets.cifar10.load_data()函数就可以直接加载切割好的训练集和数据集。\n",
    "\n",
    "TensorFlow会自动将数据集下载在 `C:\\Users\\用户名\\.keras\\datasets` 路径下，用户可以查看，也可手动删除不需要的数据集缓存。上述代码运行后，得到训练集的**x**和**y**形状为： (50000, 32, 32, 3)和(50000)，测试集的**x**和**𝒚**形状为(10000, 32, 32, 3)和(10000)，分别代表了 图片大小为32 × 32，彩色图片，训练集样本数为 50000，测试集样本数为 10000。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:45:59.615747Z",
     "start_time": "2020-02-21T03:45:42.238896Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,Sequential,optimizers,losses,datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(x,y), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "#删除y的一个维度,[b,1]=>[b]\n",
    "y=tf.squeeze(y,axis=1)\n",
    "y_test=tf.squeeze(y_test,axis=1)\n",
    "#打印训练接和测试集的形状\n",
    "print(x.shape,y.shape,x_test.shape,y_test.shape)\n",
    "\n",
    "def preprocess(x, y):\n",
    "    # 将数据映射到-1~1\n",
    "    x = 2*tf.cast(x, dtype=tf.float32) / 255. - 1\n",
    "    y = tf.cast(y, dtype=tf.int32) # 类型转换\n",
    "    return x,y\n",
    "\n",
    "#构建训练集对象，随机打乱，预处理，批量化\n",
    "train_db=tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_db=train_db.shuffle(1000).map(preprocess).batch(128)\n",
    "#构建测试集对象，预处理，批量化\n",
    "test_db=tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "test_db=test_db.map(preprocess).batch(128)\n",
    "#从训练集中采用一个Batch，并观察\n",
    "sample=next(iter(train_db))\n",
    "print('sample:',sample[0].shape,sample[1].shape,tf.reduce_min(sample[0]),tf.reduce_max(sample[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG13\n",
    "我们将基于VGG13网络，根据我们的数据集特点修改部分网络结构，完成 CIFAR10 图片识别，修改如下：\n",
    "\n",
    "1. 将网络输入调整为32×32。原网络输入为22×22，导致全连接层输入特征维度过大，网络参数量过大。\n",
    "\n",
    "2. 3个全连接层的维度调整为[256,64,10]，满足10分类任务的设定。\n",
    "\n",
    "<img src=\"VGG13.PNG\">\n",
    "\n",
    "我们将网络实现为 2个子网络：**卷积子网络**和**全连接子网络**。卷积子网络由5个子模块构成，每个子模块包含了**Conv-Conv-MaxPooling**单元结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T11:38:18.868046Z",
     "start_time": "2020-02-20T11:38:18.577822Z"
    }
   },
   "outputs": [],
   "source": [
    "#卷积子网络\n",
    "conv_layers=[\n",
    "    #先创建包含多网络的类别\n",
    "    #Conv-Conv-Pooling单元1\n",
    "    #64个3*3的卷积核，输入输出同大小\n",
    "    layers.Conv2D(64,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "    layers.Conv2D(64,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "    #高宽减半\n",
    "    layers.MaxPooling2D(pool_size=[2,2],strides=2,padding=\"same\"),\n",
    "    \n",
    "    #Conv-Conv-Pooling 单元 2,输出通道提升至 128，高宽大小减半\n",
    "    layers.Conv2D(128,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "    layers.Conv2D(128,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D(pool_size=[2,2],strides=2,padding=\"same\"),\n",
    "    \n",
    "    # Conv-Conv-Pooling 单元 3,输出通道提升至 256，高宽大小减半\n",
    "    layers.Conv2D(256,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "    layers.Conv2D(256,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D(pool_size=[2,2],strides=2,padding=\"same\"),\n",
    "    \n",
    "    # Conv-Conv-Pooling 单元 4,输出通道提升至 512，高宽大小减半\n",
    "    layers.Conv2D(512,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "    layers.Conv2D(512,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D(pool_size=[2,2],strides=2,padding=\"same\"),\n",
    "    \n",
    "    # Conv-Conv-Pooling 单元 5,输出通道提升至 512，高宽大小减半\n",
    "    layers.Conv2D(512,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "    layers.Conv2D(512,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "    layers.MaxPooling2D(pool_size=[2,2],strides=2,padding=\"same\")\n",
    "    \n",
    "    #思考：为什么越往后通道数越多\n",
    "    #回答：图片数据的识别过程一般认为也是表示学习(Representation Learning)的过程，\n",
    "    #从接受到的原始像素特征开始，逐渐提取边缘、角点等底层特征，\n",
    "    #再到纹理等中层特征，\n",
    "    #再到头 部、物体部件等高层特征。\n",
    "    #所以前面的卷积层通道少，提取的是底层特征\n",
    "    #后面的卷积和通道多，提取的是高层特征\n",
    "    \n",
    "    #思考：为什么要池化\n",
    "    ]\n",
    "\n",
    "#利用前面创建的层列表构建网络容器\n",
    "conv_net=Sequential(conv_layers)\n",
    "\n",
    "#全连接子网络\n",
    "fc_net=Sequential([\n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dense(128, activation=tf.nn.relu),\n",
    "    layers.Dense(10,activation=None)])\n",
    "\n",
    "#build两个子网络，并打印网络参数信息\n",
    "conv_net.build(input_shape=(None,32,32,3))\n",
    "fc_net.build(input_shape=(None,512))\n",
    "conv_net.summary()\n",
    "fc_net.summary()\n",
    "\n",
    "#设置学习率,默认值0.001\n",
    "optimizer=optimizers.Adam(lr=1e-4)\n",
    "#需要更新的参数\n",
    "variables=conv_net.trainable_variables+fc_net.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练并保存网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T11:38:32.432796Z",
     "start_time": "2020-02-20T11:38:26.724053Z"
    }
   },
   "outputs": [],
   "source": [
    "#模型计算\n",
    "def main():\n",
    "    for epoch in range(10):\n",
    "        for step,(x,y) in enumerate(train_db):\n",
    "            with tf.GradientTape() as tape:\n",
    "                #[b,32,32,3] => [b,1,1,512]\n",
    "                out=conv_net(x)\n",
    "                #flatten => [b,512]\n",
    "                out=tf.reshape(out,[-1,512])\n",
    "                #[b,512] => [b,10]\n",
    "                logits=fc_net(out)\n",
    "                #[b] => [b,10]\n",
    "                y_onehot=tf.one_hot(y,depth=10)\n",
    "                #compute loss\n",
    "                loss = tf.losses.categorical_crossentropy(y_onehot,logits,from_logits=True)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "            \n",
    "            grads = tape.gradient(loss,variables)\n",
    "            optimizer.apply_gradients(zip(grads,variables))\n",
    "\n",
    "            if step%100==0:\n",
    "                print(epoch,step,'loss:',float(loss))\n",
    "                \n",
    "        total_num=0\n",
    "        total_corret=0\n",
    "        for x,y in test_db:\n",
    "            out=conv_net(x)\n",
    "            out=tf.reshape(out,[-1,512])\n",
    "            logits=fc_net(out)\n",
    "            prob=tf.nn.softmax(logits,axis=1)\n",
    "            pred=tf.argmax(prob,axis=1)\n",
    "            pred=tf.cast(pred,dtype=tf.int32)\n",
    "            \n",
    "            correct=tf.cast(tf.equal(pred,y),dtype=tf.int32)\n",
    "            correct=tf.reduce_sum(correct)\n",
    "            \n",
    "            total_num+=x.shape[0]\n",
    "            total_corret+=int(correct)\n",
    "        \n",
    "        acc=total_corret/total_num\n",
    "        print(epoch,'acc:',acc)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save and load the model**\n",
    "\n",
    "High level keras `model.save` and `tf.keras.models.load_model`\n",
    "\n",
    "```\n",
    "keras_model_path = \"/tmp/keras_save\"\n",
    "model.save(keras_model_path)  # save() should be called out of strategy scope\n",
    "```\n",
    "\n",
    "Low level `tf.saved_model.save` and `tf.saved_model.load`\n",
    "\n",
    "即SavedModel方式，TensorFlow之所以能够被业界青睐，除了优秀的神经网络层API支持之外，还得益于它强大的生态系统，包括移动端和网页端等的支持。当需要将模型部署到其他平台时，采用 TensorFlow提出的SavedModel方式更具有平台无关性。\n",
    "\n",
    "参考网址:\n",
    "\n",
    "https://www.tensorflow.org/tutorials/distribute/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T16:23:05.467303Z",
     "start_time": "2020-02-11T16:23:05.213953Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_net.save('conv_net.h5') \n",
    "print('saving conv-net')\n",
    "#del conv_net#删除网络对象\n",
    "fc_net.save('fc_net.h5') \n",
    "print('saving fc_net.')\n",
    "#del fc_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载网络\n",
    "```\n",
    "restored_keras_model = tf.keras.models.load_model(keras_model_path)\n",
    "restored_keras_model.fit(train_dataset, epochs=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:46:35.933087Z",
     "start_time": "2020-02-21T03:46:35.472854Z"
    }
   },
   "outputs": [],
   "source": [
    "print('load conv_net from file.')\n",
    "conv_net = keras.models.load_model('conv_net.h5')\n",
    "print('load fc_net from file.')\n",
    "fc_net = keras.models.load_model('fc_net.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
    "            \n",
    "见：[userwarning-no-training-configuration-found-in-save-file-the-model-was-not-c](https://stackoverflow.com/questions/53295570/userwarning-no-training-configuration-found-in-save-file-the-model-was-not-c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 剪裁并显示图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:46:52.234506Z",
     "start_time": "2020-02-21T03:46:51.792024Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#读取图片\n",
    "import imageio\n",
    "image_value = imageio.imread('cat.jpg')\n",
    "plt.imshow(image_value)\n",
    "plt.show()\n",
    "\n",
    "image_value=tf.image.resize(image_value,[32,32],antialias=True)\n",
    "image_value=tf.cast(image_value,tf.int32)\n",
    "plt.imshow(image_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出图片识别结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:46:57.791859Z",
     "start_time": "2020-02-21T03:46:57.785873Z"
    }
   },
   "outputs": [],
   "source": [
    "transfer=dict({0:\"airplane\",\n",
    "        1:\"automobile\",\n",
    "        2:\"bird\",\n",
    "        3:\"cat\",\n",
    "        4:\"deer\",\n",
    "        5:\"dog\",\n",
    "        6:\"frog\",\n",
    "        7:\"horse\",\n",
    "        8:\"ship\",\n",
    "        9:\"truck\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:46:58.474767Z",
     "start_time": "2020-02-21T03:46:58.463796Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test(file_name):\n",
    "    image_value=imageio.imread(file_name)[::,::,0:3]#因为读进来时是四通道\n",
    "    plt.imshow(image_value)\n",
    "    image_value=tf.image.resize(image_value,[32,32],antialias=True)\n",
    "    image_value=tf.expand_dims(image_value,axis=0)\n",
    "    image_value=2*tf.cast(image_value, dtype=tf.float32) / 255. - 1\n",
    "    out=conv_net(image_value)     \n",
    "    out=tf.reshape(out,[-1,512])\n",
    "    logits=fc_net(out)\n",
    "    res=tf.argmax(logits,axis=1)\n",
    "    plt.xlabel(transfer[int(res)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T03:47:04.407035Z",
     "start_time": "2020-02-21T03:46:59.375971Z"
    }
   },
   "outputs": [],
   "source": [
    "file_name=\"cat.jpg\"\n",
    "test(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若报错：Failed to get convolution algorithm. This is probably because cuDNN failed to initialize,...\n",
    "\n",
    "可能原因是GPU内存不足造成的（重启内核）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "129px",
    "width": "296px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
