{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T07:42:20.019265Z",
     "start_time": "2020-02-21T07:42:19.926484Z"
    }
   },
   "source": [
    "# AutoEncoder实现FashionMNIST图片重建实战\n",
    "\n",
    "## Fashion MNIST\n",
    "\n",
    "Fashion MNIST 是一个定位在比MNIST图片识别问题稍复杂的数据集，它的设定与MNIST几乎完全一样，包含了10类不同类型的衣服、鞋子、包等灰度图片，图片大小为 28 × 28，共 70000 张图片，其中 60000 张用于训练集，10000 张用于测试集，如下图所示，每行是一种类别图片。可以看到，Fashion MNIST除了图片内容与MNIST不一样， 其它设定都相同，大部分情况可以直接替换掉原来基于MNIST训练的算法代码，而不需要额外修改。由于 Fashion MNIST图片识别相对于MNIST 图片更难，因此可以用于测试稍复杂的算法性能。\n",
    "\n",
    "<img src=\"FashionMNIST.PNG\" width=\"50%\">\n",
    "\n",
    "[Fashion MNIST官网](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "[更多Keras内置数据集](https://www.tensorflow.org/datasets/catalog/fashion_mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T07:56:43.071146Z",
     "start_time": "2020-02-21T07:56:23.327433Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,Sequential,optimizers,losses,datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons \n",
    "from sklearn.model_selection import train_test_split\n",
    "import imageio\n",
    "from PIL import Image\n",
    "\n",
    "# 加载 Fashion MNIST 图片数据集\n",
    "(x_train,y_train),(x_test, y_test)=keras.datasets.fashion_mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "#归一化\n",
    "x_train,x_test=x_train.astype(np.float32)/255.,x_test.astype(np.float32)/255.\n",
    "#只需要通过图片数据构建数据集对象，不需要标签\n",
    "batchsz=256\n",
    "train_db=tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_db=train_db.shuffle(batchsz*5).batch(batchsz)\n",
    "test_db=tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_db=test_db.batch(batchsz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Encoder\n",
    "\n",
    "我们尝试着利用数据$x$本身作为监督信号来指导网络的训练，即希望神经网络能够学习到映射$f_\\theta :x\\to x$。\n",
    "\n",
    "我们把网络$f_\\theta$切分为两个部分，前面的子网络尝试学习映射关 系:$g_{\\theta 1}: x\\to z$，后面的子网络尝试学习映射关系$h_{\\theta 2}:z\\to x$，如图下图所示。\n",
    "\n",
    "<img src=\"autoencoder_f.PNG\" width=\"30%\">\n",
    "\n",
    "\n",
    "我们把$g_{\\theta 1}$成一个数据编码(Encode)的过程，把高维度的输入$x$编码成低维度的隐变量$z$(Latent Variable，或隐藏变量)，称为**Encoder网络(编码器)**；$h_{\\theta 2}$编码过后的输入$z$解码为高维度的$x$，称为**Decoder网络(解码器)**。\n",
    "\n",
    "编码器和解码器共同完成了输入数据$x$的编码和解码过程，我们把整个网络模型$f_\\theta$叫做**自动编码器(Auto-Encoder)**，简称自编码器。如果使用深层神经网络来参数化$g_{\\theta 1}$和$h_{\\theta 2}$函数，则称为**深度自编码器(Deep Auto-encoder)**。如下图所示。\n",
    "\n",
    "<img src=\"Deep_AutoEncoder.PNG\" width=\"50%\">\n",
    "\n",
    "自编码器能够将输入变换到隐藏向量$z$，并通过解码器重建(Reconstruct，或恢复)出$x$。我们希望解码器的输出能够完美地或者近似恢复出原来的输入，即$x\\approx \\overline{x}$，那么，自编码器的优化目标可以写成：\n",
    "\n",
    "$$\n",
    "Minimize\\ \\ \\  \\zeta = dist(x,\\overline{x})\\\\\n",
    "\\overline{x} = h_{\\theta 2}(g_{\\theta 1}(x))\n",
    "$$\n",
    "\n",
    "其中$dist(x,\\overline{x})$表示$x$和$\\overline{x}$的距离度量，称为重建误差函数。最常见的度量方法有欧氏距离 (Euclidean distance)的平方，计算方法如下：\n",
    "\n",
    "$$\n",
    "\\zeta = \\sum_i(x_i-\\overline{x_i})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现\n",
    "\n",
    "我们利用编码器将输入图片$x\\in R^{784}$降维到较低维度的隐藏向量： $h\\in R^{20}$，并基于隐藏向量利用解码器重建图片，自编码器模型下图所示，编码器由3层全连接层网络组成，输出节点数分别为256、128、20，解码器同样由3层全连接网络组成，输出节点数分别为128、256、784。\n",
    "\n",
    "<img src=\"FashionMNIST_AutoEncoder.PNG\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T08:42:15.249956Z",
     "start_time": "2020-02-21T08:42:15.229010Z"
    }
   },
   "outputs": [],
   "source": [
    "class AE(keras.Model):\n",
    "    #自编码器模型类，包括了Encoder和Decoder2个子网络\n",
    "    def __init__(self):\n",
    "        super(AE,self).__init__()\n",
    "        #创建Encoders网络\n",
    "        \n",
    "        h_dim=30\n",
    "        \n",
    "        #创建Encoders网络，实现在自编码器类的初始化函数中\n",
    "        self.encoder=Sequential([\n",
    "            layers.Dense(256,activation=tf.nn.relu),\n",
    "            layers.Dense(128,activation=tf.nn.relu),\n",
    "            layers.Dense(h_dim)\n",
    "            ])\n",
    "        \n",
    "        \n",
    "        #创建Decoders网络\n",
    "        self.decoder=Sequential([\n",
    "            layers.Dense(128,activation=tf.nn.relu),\n",
    "            layers.Dense(256,activation=tf.nn.relu),\n",
    "            layers.Dense(784)\n",
    "            ])\n",
    "       \n",
    "    #接下来将前向传播过程实现在 call 函数中，输入图片首先通过 encoder 子网络得到隐\n",
    "    #藏向量 h，再通过 decoder 得到重建图片。依次调用编码器和解码器的前向传播函数即可\n",
    "        \n",
    "    def call(self,inputs,training=None):\n",
    "        #前向传播函数\n",
    "        #获得隐藏向量h,[b,784] => [b,20]\n",
    "        h=self.encoder(inputs)\n",
    "        #解码获得重建图片,[b,20] => [b,784]\n",
    "        x_hat=self.decoder(h)\n",
    "        \n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练与保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T08:55:01.651262Z",
     "start_time": "2020-02-21T08:43:42.838890Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#创建网络对象\n",
    "model = AE()\n",
    "model.build(input_shape=(None,784))\n",
    "model.summary()\n",
    "optimizer=optimizers.Adam(lr=1e-4)\n",
    "\n",
    "for epoch in range(120):\n",
    "    for step,x in enumerate(train_db):\n",
    "        # 打平，[b, 28, 28] => [b, 784]\n",
    "        x=tf.reshape(x,[-1,784])\n",
    "        #构建梯度记录器\n",
    "        with tf.GradientTape() as tape:\n",
    "            #前向计算重新获得构建的图片\n",
    "            x_rec_logits=model(x)\n",
    "            #计算构建图片与输入之间的损失函数\n",
    "            rec_loss=tf.nn.sigmoid_cross_entropy_with_logits(labels=x,logits=x_rec_logits)\n",
    "            #计算均值\n",
    "            rec_loss=tf.reduce_mean(rec_loss)\n",
    "        #自动求导，包含2个子网络的梯度\n",
    "        grads=tape.gradient(rec_loss,model.trainable_variables)\n",
    "        #自动更新，同时更新2个子网络\n",
    "        optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "        \n",
    "        if step%100==0:\n",
    "            print(epoch,step,float(rec_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Autoencoder_FM_weights.ckpt') \n",
    "print('saved weights.')\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型加载与运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T09:02:28.189276Z",
     "start_time": "2020-02-21T09:02:28.123454Z"
    }
   },
   "outputs": [],
   "source": [
    "model=AE()\n",
    "model.load_weights('Autoencoder_FM_weights.ckpt') \n",
    "print('loaded weights!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`save_images`函数负责将多张图片合并并保存为一张大图，这部分代码使用PIL图片库完成图片阵列逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T09:02:11.192696Z",
     "start_time": "2020-02-21T09:02:11.132854Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_images(imgs,name):\n",
    "    #创建280*280大小的图片阵列\n",
    "    new_im=Image.new('L',(280,280))\n",
    "    index=0\n",
    "    for i in range(0,280,28):\n",
    "        for j in range(0,280,28):\n",
    "            im=imgs[index]\n",
    "            im=Image.fromarray(im,mode='L')\n",
    "            new_im.paste(im,(i,j))#写入对应位置\n",
    "            index+=1\n",
    "    #保存图片阵列\n",
    "    new_im.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T09:02:31.462547Z",
     "start_time": "2020-02-21T09:02:31.196245Z"
    }
   },
   "outputs": [],
   "source": [
    "x=next(iter(test_db))\n",
    "logits=model(tf.reshape(x,[-1,784]))\n",
    "x_hat=tf.sigmoid(logits)\n",
    "x_hat=tf.reshape(x_hat,[-1,28,28])\n",
    "\n",
    "#输入的前50张+重建的前50张图片合并，[b,28,28]=>[2b,28,28]\n",
    "x_concat=tf.concat([x[:50],x_hat[:50]],axis=0)\n",
    "x_concat=x_concat.numpy()*255.\n",
    "x_concat=x_concat.astype(np.uint8)#转换为整型\n",
    "save_images(x_concat,'AutoEncoder_FashionMNIST.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T09:03:35.745745Z",
     "start_time": "2020-02-21T09:03:35.290960Z"
    }
   },
   "outputs": [],
   "source": [
    "image_value = imageio.imread('AutoEncoder_FashionMNIST.png')\n",
    "plt.imshow(image_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
